use anyhow::Result;
use tch::{nn, nn::Module, nn::OptimizerConfig, Device, Tensor};

pub struct TorchStockModel {
    input_proj: nn::Linear,
    lstm: Option<nn::LSTM>,
    lstm_to_transformer: Option<nn::Linear>,
    transformer: TransformerEncoder,
    output_proj: nn::Linear,
}

struct TransformerEncoder {
    layers: Vec<TransformerEncoderLayer>,
}

struct TransformerEncoderLayer {
    self_attn: nn::Linear,
    feed_forward: nn::Sequential,
    norm1: nn::LayerNorm,
    norm2: nn::LayerNorm,
}
config: &ModelConfig) -> Self {
        let input_proj = nn::linear(vs / "input_proj", 86, config.d_model, Default::default());
        
        // LSTM layers for temporal feature extraction
        let (lstm, lstm_to_transformer) = if config.use_lstm {
            let lstm_config = nn::RNNConfig {
                num_layers: config.lstm_layers,
                dropout: 0.1,
                bidirectional: true,
                ..Default::default()
            };
            let lstm = nn::lstm(vs / "lstm", config.d_model, config.lstm_hidden, lstm_config);
            // Bidirectional LSTM outputs lstm_hidden * 2
            let proj = nn::linear(vs / "lstm_proj", config.lstm_hidden * 2, config.d_model, Default::default());
            (Some(lstm), Some(proj))
        } else {
            (None, None)
        };
        
        let mut layers = Vec::new();
        for i in 0..config.n_layers {
            let layer_path = vs / format!("layer_{}", i);
            layers.push(TransformerEncoderLayer::new(&layer_path, config.d_model, config.n_heads, config.d_ff));
        }
        
        // LSTM for temporal processing if enabled
        let x = if let (Some(lstm), Some(proj)) = (&self.lstm, &self.lstm_to_transformer) {
            // LSTM expects (seq_len, batch, features)
            let x = x.permute(&[1, 0, 2]);
            let (lstm_out, _) = lstm.seq(&x);
            // Convert back to (batch, seq_len, features)
            let lstm_out = lstm_out.permute(&[1, 0, 2]);
            let lstm_out = proj.forward(&lstm_out);
            if train { lstm_out.dropout(0.1, true) } else { lstm_out }
        } else {
            x
        };
        
        // Transformer for attention-based refinement
        
        let transformer = TransformerEncoder { layers };
        let output_proj = nn::linear(vs / "output_proj", config.d_model, 86, Default::default());
        
        Self {
            input_proj,
            lstm,
            lstm_to_transformer
        Self {
            input_proj,
            transformer,
            output_proj,
        }
    }
    
    pub fn forward(&self, input: &Tensor, train: bool) -> Tensor {
        let x = self.input_proj.forward(input);
        let x = if train { x.dropout(0.1, true) } else { x };
        let x = self.transformer.forward(&x, train);
        self.output_proj.forward(&x)
    }
}

impl TransformerEncoderLayer {
    fn new(vs: &nn::Path, d_model: i64, _n_heads: i64, d_ff: i64) -> Self {
        let self_attn = nn::linear(vs / "attn", d_model, d_model, Default::default());
        
        let feed_forward = nn::seq()
            .add(nn::linear(vs / "ff1", d_model, d_ff, Default::default()))
            .add_fn(|x: &Tensor| x.relu())
            .add_fn(|x: &Tensor| x.dropout(0.1, true))
            .add(nn::linear(vs / "ff2", d_ff, d_model, Default::default()));
        
        let norm1 = nn::layer_norm(vs / "norm1", vec![d_model], Default::default());
        let norm2 = nn::layer_norm(vs / "norm2", vec![d_model], Default::default());
        
        Self {
            self_attn,
            feed_forward,
            norm1,
            norm2,
        }
    }
    
    fn forward(&self, x: &Tensor, train: bool) -> Tensor {
        let attn_out = self.self_attn.forward(x);
        let attn_out = if train { attn_out.dropout(0.1, true) } else { attn_out };
        let x = (x + attn_out).apply(&self.norm1);
        let ff_out = self.feed_forward.forward(&x);
        (x + ff_out).apply(&self.norm2)
    }
}

impl TransformerEncoder {
    fn forward(&self, x: &Tensor, train: bool) -> Tensor {
        let mut output = x.shallow_clone();
        for layer in &self.layers {
            output = layer.forward(&output, train);
        }
        output
    }
}

pub struct ModelConfig {
    pub d_model: i64,
    pub n_heads: i64,
    pub n_layers: i64,
    pub d_ff: i64,
    pub lstm_hidden: i64,
    pub lstm_layers: i64,
    pub use_lstm: bool,
}

impl Default for ModelConfig {
    fn default() -> Self {
        Self {
            d_model: 384,   // Balanced capacity
            n_heads: 8,
            n_layers: 5,    // Moderate depth
            d_ff: 1536,     // Balanced FF dimension
            lstm_hidden: 256, // LSTM hidden dimension
            lstm_layers: 2,   // Number of LSTM layers
            use_lstm: true,   // Enable LSTM by default
        }
    }
}
